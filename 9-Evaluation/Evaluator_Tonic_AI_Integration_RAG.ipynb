{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: llama-index in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (0.12.6)\n",
      "Requirement already satisfied: llama-index-agent-openai<0.5.0,>=0.4.0 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from llama-index) (0.4.0)\n",
      "Requirement already satisfied: llama-index-cli<0.5.0,>=0.4.0 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from llama-index) (0.4.0)\n",
      "Requirement already satisfied: llama-index-core<0.13.0,>=0.12.6 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from llama-index) (0.12.6)\n",
      "Requirement already satisfied: llama-index-embeddings-openai<0.4.0,>=0.3.0 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from llama-index) (0.3.1)\n",
      "Requirement already satisfied: llama-index-indices-managed-llama-cloud>=0.4.0 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from llama-index) (0.6.3)\n",
      "Requirement already satisfied: llama-index-llms-openai<0.4.0,>=0.3.0 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from llama-index) (0.3.10)\n",
      "Requirement already satisfied: llama-index-multi-modal-llms-openai<0.5.0,>=0.4.0 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from llama-index) (0.4.0)\n",
      "Requirement already satisfied: llama-index-program-openai<0.4.0,>=0.3.0 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from llama-index) (0.3.1)\n",
      "Requirement already satisfied: llama-index-question-gen-openai<0.4.0,>=0.3.0 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from llama-index) (0.3.0)\n",
      "Requirement already satisfied: llama-index-readers-file<0.5.0,>=0.4.0 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from llama-index) (0.4.1)\n",
      "Requirement already satisfied: llama-index-readers-llama-parse>=0.4.0 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from llama-index) (0.4.0)\n",
      "Requirement already satisfied: nltk>3.8.1 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from llama-index) (3.9.1)\n",
      "Requirement already satisfied: openai>=1.14.0 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from llama-index-agent-openai<0.5.0,>=0.4.0->llama-index) (1.57.4)\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.6->llama-index) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.6->llama-index) (2.0.32)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.6->llama-index) (3.10.8)\n",
      "Requirement already satisfied: dataclasses-json in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.6->llama-index) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.6->llama-index) (1.2.14)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.6->llama-index) (1.0.8)\n",
      "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.6->llama-index) (1.2.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.6->llama-index) (2024.9.0)\n",
      "Requirement already satisfied: httpx in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.6->llama-index) (0.27.2)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.6->llama-index) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.6->llama-index) (3.4.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.6->llama-index) (1.26.4)\n",
      "Requirement already satisfied: pillow>=9.0.0 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.6->llama-index) (10.4.0)\n",
      "Requirement already satisfied: pydantic>=2.8.0 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.6->llama-index) (2.9.2)\n",
      "Requirement already satisfied: requests>=2.31.0 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.6->llama-index) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.6->llama-index) (8.5.0)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.6->llama-index) (0.7.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.6->llama-index) (4.67.0)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.6->llama-index) (4.11.0)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.6->llama-index) (0.9.0)\n",
      "Requirement already satisfied: wrapt in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.6->llama-index) (1.16.0)\n",
      "Requirement already satisfied: llama-cloud>=0.1.5 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from llama-index-indices-managed-llama-cloud>=0.4.0->llama-index) (0.1.6)\n",
      "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (4.12.3)\n",
      "Requirement already satisfied: pandas in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (2.2.3)\n",
      "Requirement already satisfied: pypdf<6.0.0,>=5.1.0 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (5.1.0)\n",
      "Requirement already satisfied: striprtf<0.0.27,>=0.0.26 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (0.0.26)\n",
      "Requirement already satisfied: llama-parse>=0.5.0 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from llama-index-readers-llama-parse>=0.4.0->llama-index) (0.5.13)\n",
      "Requirement already satisfied: click in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from nltk>3.8.1->llama-index) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from nltk>3.8.1->llama-index) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from nltk>3.8.1->llama-index) (2024.11.6)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.6->llama-index) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.6->llama-index) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.6->llama-index) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.6->llama-index) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.6->llama-index) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.6->llama-index) (1.17.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (2.6)\n",
      "Requirement already satisfied: anyio in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from httpx->llama-index-core<0.13.0,>=0.12.6->llama-index) (4.6.2.post1)\n",
      "Requirement already satisfied: certifi in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from httpx->llama-index-core<0.13.0,>=0.12.6->llama-index) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from httpx->llama-index-core<0.13.0,>=0.12.6->llama-index) (1.0.6)\n",
      "Requirement already satisfied: idna in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from httpx->llama-index-core<0.13.0,>=0.12.6->llama-index) (3.10)\n",
      "Requirement already satisfied: sniffio in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from httpx->llama-index-core<0.13.0,>=0.12.6->llama-index) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from httpcore==1.*->httpx->llama-index-core<0.13.0,>=0.12.6->llama-index) (0.14.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from click->nltk>3.8.1->llama-index) (0.4.6)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from openai>=1.14.0->llama-index-agent-openai<0.5.0,>=0.4.0->llama-index) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from openai>=1.14.0->llama-index-agent-openai<0.5.0,>=0.4.0->llama-index) (0.7.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.6->llama-index) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.6->llama-index) (2.23.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.6->llama-index) (3.4.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.6->llama-index) (2.2.3)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.6->llama-index) (3.1.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from typing-inspect>=0.8.0->llama-index-core<0.13.0,>=0.12.6->llama-index) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from dataclasses-json->llama-index-core<0.13.0,>=0.12.6->llama-index) (3.23.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from pandas->llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from pandas->llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from pandas->llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (2024.2)\n",
      "Requirement already satisfied: packaging>=17.0 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.13.0,>=0.12.6->llama-index) (23.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (1.16.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from yarl<2.0,>=1.12.0->aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.6->llama-index) (0.2.0)\n",
      "Requirement already satisfied: tonic-validate in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (6.2.0)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: aioboto3<13.0.0,>=12.4.0 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from tonic-validate) (12.4.0)\n",
      "Requirement already satisfied: appdirs<2.0.0,>=1.4.4 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from tonic-validate) (1.4.4)\n",
      "Requirement already satisfied: google-generativeai<0.6.0,>=0.5.2 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from tonic-validate) (0.5.4)\n",
      "Requirement already satisfied: litellm<2.0.0,>=1.35.8 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from tonic-validate) (1.55.7)\n",
      "Requirement already satisfied: openai>=1.0.0 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from tonic-validate) (1.57.4)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.6.4 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from tonic-validate) (2.9.2)\n",
      "Requirement already satisfied: python-dotenv<2.0.0,>=1.0.1 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from tonic-validate) (1.0.1)\n",
      "Requirement already satisfied: tiktoken<0.8.0,>=0.7.0 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from tonic-validate) (0.7.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.2 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from tonic-validate) (4.67.0)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.10.0 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from tonic-validate) (4.11.0)\n",
      "Requirement already satisfied: aiobotocore==2.12.3 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from aiobotocore[boto3]==2.12.3->aioboto3<13.0.0,>=12.4.0->tonic-validate) (2.12.3)\n",
      "Requirement already satisfied: botocore<1.34.70,>=1.34.41 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from aiobotocore==2.12.3->aiobotocore[boto3]==2.12.3->aioboto3<13.0.0,>=12.4.0->tonic-validate) (1.34.69)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.7.4.post0 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from aiobotocore==2.12.3->aiobotocore[boto3]==2.12.3->aioboto3<13.0.0,>=12.4.0->tonic-validate) (3.10.8)\n",
      "Requirement already satisfied: wrapt<2.0.0,>=1.10.10 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from aiobotocore==2.12.3->aiobotocore[boto3]==2.12.3->aioboto3<13.0.0,>=12.4.0->tonic-validate) (1.16.0)\n",
      "Requirement already satisfied: aioitertools<1.0.0,>=0.5.1 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from aiobotocore==2.12.3->aiobotocore[boto3]==2.12.3->aioboto3<13.0.0,>=12.4.0->tonic-validate) (0.12.0)\n",
      "Requirement already satisfied: boto3<1.34.70,>=1.34.41 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from aiobotocore[boto3]==2.12.3->aioboto3<13.0.0,>=12.4.0->tonic-validate) (1.34.69)\n",
      "Requirement already satisfied: google-ai-generativelanguage==0.6.4 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from google-generativeai<0.6.0,>=0.5.2->tonic-validate) (0.6.4)\n",
      "Requirement already satisfied: google-api-core in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from google-generativeai<0.6.0,>=0.5.2->tonic-validate) (2.23.0)\n",
      "Requirement already satisfied: google-api-python-client in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from google-generativeai<0.6.0,>=0.5.2->tonic-validate) (2.151.0)\n",
      "Requirement already satisfied: google-auth>=2.15.0 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from google-generativeai<0.6.0,>=0.5.2->tonic-validate) (2.36.0)\n",
      "Requirement already satisfied: protobuf in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from google-generativeai<0.6.0,>=0.5.2->tonic-validate) (4.25.5)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from google-ai-generativelanguage==0.6.4->google-generativeai<0.6.0,>=0.5.2->tonic-validate) (1.25.0)\n",
      "Requirement already satisfied: click in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from litellm<2.0.0,>=1.35.8->tonic-validate) (8.1.7)\n",
      "Requirement already satisfied: httpx<0.28.0,>=0.23.0 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from litellm<2.0.0,>=1.35.8->tonic-validate) (0.27.2)\n",
      "Requirement already satisfied: importlib-metadata>=6.8.0 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from litellm<2.0.0,>=1.35.8->tonic-validate) (8.4.0)\n",
      "Requirement already satisfied: jinja2<4.0.0,>=3.1.2 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from litellm<2.0.0,>=1.35.8->tonic-validate) (3.1.4)\n",
      "Requirement already satisfied: jsonschema<5.0.0,>=4.22.0 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from litellm<2.0.0,>=1.35.8->tonic-validate) (4.23.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.31.0 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from litellm<2.0.0,>=1.35.8->tonic-validate) (2.32.3)\n",
      "Requirement already satisfied: tokenizers in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from litellm<2.0.0,>=1.35.8->tonic-validate) (0.20.3)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from openai>=1.0.0->tonic-validate) (4.6.2.post1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from openai>=1.0.0->tonic-validate) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from openai>=1.0.0->tonic-validate) (0.7.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from openai>=1.0.0->tonic-validate) (1.3.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from pydantic<3.0.0,>=2.6.4->tonic-validate) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from pydantic<3.0.0,>=2.6.4->tonic-validate) (2.23.4)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from tiktoken<0.8.0,>=0.7.0->tonic-validate) (2024.11.6)\n",
      "Requirement already satisfied: colorama in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from tqdm<5.0.0,>=4.66.2->tonic-validate) (0.4.6)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from aiohttp<4.0.0,>=3.7.4.post0->aiobotocore==2.12.3->aiobotocore[boto3]==2.12.3->aioboto3<13.0.0,>=12.4.0->tonic-validate) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from aiohttp<4.0.0,>=3.7.4.post0->aiobotocore==2.12.3->aiobotocore[boto3]==2.12.3->aioboto3<13.0.0,>=12.4.0->tonic-validate) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from aiohttp<4.0.0,>=3.7.4.post0->aiobotocore==2.12.3->aiobotocore[boto3]==2.12.3->aioboto3<13.0.0,>=12.4.0->tonic-validate) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from aiohttp<4.0.0,>=3.7.4.post0->aiobotocore==2.12.3->aiobotocore[boto3]==2.12.3->aioboto3<13.0.0,>=12.4.0->tonic-validate) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from aiohttp<4.0.0,>=3.7.4.post0->aiobotocore==2.12.3->aiobotocore[boto3]==2.12.3->aioboto3<13.0.0,>=12.4.0->tonic-validate) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from aiohttp<4.0.0,>=3.7.4.post0->aiobotocore==2.12.3->aiobotocore[boto3]==2.12.3->aioboto3<13.0.0,>=12.4.0->tonic-validate) (1.17.1)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from anyio<5,>=3.5.0->openai>=1.0.0->tonic-validate) (3.10)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from google-api-core->google-generativeai<0.6.0,>=0.5.2->tonic-validate) (1.63.2)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai<0.6.0,>=0.5.2->tonic-validate) (5.5.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai<0.6.0,>=0.5.2->tonic-validate) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai<0.6.0,>=0.5.2->tonic-validate) (4.9)\n",
      "Requirement already satisfied: certifi in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from httpx<0.28.0,>=0.23.0->litellm<2.0.0,>=1.35.8->tonic-validate) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from httpx<0.28.0,>=0.23.0->litellm<2.0.0,>=1.35.8->tonic-validate) (1.0.6)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from httpcore==1.*->httpx<0.28.0,>=0.23.0->litellm<2.0.0,>=1.35.8->tonic-validate) (0.14.0)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from importlib-metadata>=6.8.0->litellm<2.0.0,>=1.35.8->tonic-validate) (3.21.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from jinja2<4.0.0,>=3.1.2->litellm<2.0.0,>=1.35.8->tonic-validate) (3.0.2)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from jsonschema<5.0.0,>=4.22.0->litellm<2.0.0,>=1.35.8->tonic-validate) (2024.10.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from jsonschema<5.0.0,>=4.22.0->litellm<2.0.0,>=1.35.8->tonic-validate) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from jsonschema<5.0.0,>=4.22.0->litellm<2.0.0,>=1.35.8->tonic-validate) (0.21.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from requests<3.0.0,>=2.31.0->litellm<2.0.0,>=1.35.8->tonic-validate) (3.4.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from requests<3.0.0,>=2.31.0->litellm<2.0.0,>=1.35.8->tonic-validate) (2.2.3)\n",
      "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from google-api-python-client->google-generativeai<0.6.0,>=0.5.2->tonic-validate) (0.22.0)\n",
      "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from google-api-python-client->google-generativeai<0.6.0,>=0.5.2->tonic-validate) (0.2.0)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from google-api-python-client->google-generativeai<0.6.0,>=0.5.2->tonic-validate) (4.1.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from tokenizers->litellm<2.0.0,>=1.35.8->tonic-validate) (0.23.5)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from boto3<1.34.70,>=1.34.41->aiobotocore[boto3]==2.12.3->aioboto3<13.0.0,>=12.4.0->tonic-validate) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from boto3<1.34.70,>=1.34.41->aiobotocore[boto3]==2.12.3->aioboto3<13.0.0,>=12.4.0->tonic-validate) (0.10.3)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from botocore<1.34.70,>=1.34.41->aiobotocore==2.12.3->aiobotocore[boto3]==2.12.3->aioboto3<13.0.0,>=12.4.0->tonic-validate) (2.8.2)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.4->google-generativeai<0.6.0,>=0.5.2->tonic-validate) (1.67.1)\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.4->google-generativeai<0.6.0,>=0.5.2->tonic-validate) (1.62.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client->google-generativeai<0.6.0,>=0.5.2->tonic-validate) (3.2.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm<2.0.0,>=1.35.8->tonic-validate) (3.16.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm<2.0.0,>=1.35.8->tonic-validate) (2024.9.0)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm<2.0.0,>=1.35.8->tonic-validate) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm<2.0.0,>=1.35.8->tonic-validate) (6.0.2)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai<0.6.0,>=0.5.2->tonic-validate) (0.6.1)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from yarl<2.0,>=1.12.0->aiohttp<4.0.0,>=3.7.4.post0->aiobotocore==2.12.3->aiobotocore[boto3]==2.12.3->aioboto3<13.0.0,>=12.4.0->tonic-validate) (0.2.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.34.70,>=1.34.41->aiobotocore==2.12.3->aiobotocore[boto3]==2.12.3->aioboto3<13.0.0,>=12.4.0->tonic-validate) (1.16.0)\n",
      "Requirement already satisfied: llama-index-evaluation-tonic-validate in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (0.4.0)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: aioboto3<13.0.0,>=12.4.0 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from llama-index-evaluation-tonic-validate) (12.4.0)\n",
      "Requirement already satisfied: llama-index-core<0.13.0,>=0.12.0 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from llama-index-evaluation-tonic-validate) (0.12.6)\n",
      "Requirement already satisfied: tonic-validate<7.0.0,>=6.1.0 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from llama-index-evaluation-tonic-validate) (6.2.0)\n",
      "Requirement already satisfied: aiobotocore==2.12.3 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from aiobotocore[boto3]==2.12.3->aioboto3<13.0.0,>=12.4.0->llama-index-evaluation-tonic-validate) (2.12.3)\n",
      "Requirement already satisfied: botocore<1.34.70,>=1.34.41 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from aiobotocore==2.12.3->aiobotocore[boto3]==2.12.3->aioboto3<13.0.0,>=12.4.0->llama-index-evaluation-tonic-validate) (1.34.69)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.7.4.post0 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from aiobotocore==2.12.3->aiobotocore[boto3]==2.12.3->aioboto3<13.0.0,>=12.4.0->llama-index-evaluation-tonic-validate) (3.10.8)\n",
      "Requirement already satisfied: wrapt<2.0.0,>=1.10.10 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from aiobotocore==2.12.3->aiobotocore[boto3]==2.12.3->aioboto3<13.0.0,>=12.4.0->llama-index-evaluation-tonic-validate) (1.16.0)\n",
      "Requirement already satisfied: aioitertools<1.0.0,>=0.5.1 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from aiobotocore==2.12.3->aiobotocore[boto3]==2.12.3->aioboto3<13.0.0,>=12.4.0->llama-index-evaluation-tonic-validate) (0.12.0)\n",
      "Requirement already satisfied: boto3<1.34.70,>=1.34.41 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from aiobotocore[boto3]==2.12.3->aioboto3<13.0.0,>=12.4.0->llama-index-evaluation-tonic-validate) (1.34.69)\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-evaluation-tonic-validate) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.0->llama-index-evaluation-tonic-validate) (2.0.32)\n",
      "Requirement already satisfied: dataclasses-json in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-evaluation-tonic-validate) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-evaluation-tonic-validate) (1.2.14)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-evaluation-tonic-validate) (1.0.8)\n",
      "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-evaluation-tonic-validate) (1.2.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-evaluation-tonic-validate) (2024.9.0)\n",
      "Requirement already satisfied: httpx in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-evaluation-tonic-validate) (0.27.2)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-evaluation-tonic-validate) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-evaluation-tonic-validate) (3.4.2)\n",
      "Requirement already satisfied: nltk>3.8.1 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-evaluation-tonic-validate) (3.9.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-evaluation-tonic-validate) (1.26.4)\n",
      "Requirement already satisfied: pillow>=9.0.0 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-evaluation-tonic-validate) (10.4.0)\n",
      "Requirement already satisfied: pydantic>=2.8.0 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-evaluation-tonic-validate) (2.9.2)\n",
      "Requirement already satisfied: requests>=2.31.0 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-evaluation-tonic-validate) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-evaluation-tonic-validate) (8.5.0)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-evaluation-tonic-validate) (0.7.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-evaluation-tonic-validate) (4.67.0)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-evaluation-tonic-validate) (4.11.0)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-evaluation-tonic-validate) (0.9.0)\n",
      "Requirement already satisfied: appdirs<2.0.0,>=1.4.4 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from tonic-validate<7.0.0,>=6.1.0->llama-index-evaluation-tonic-validate) (1.4.4)\n",
      "Requirement already satisfied: google-generativeai<0.6.0,>=0.5.2 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from tonic-validate<7.0.0,>=6.1.0->llama-index-evaluation-tonic-validate) (0.5.4)\n",
      "Requirement already satisfied: litellm<2.0.0,>=1.35.8 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from tonic-validate<7.0.0,>=6.1.0->llama-index-evaluation-tonic-validate) (1.55.7)\n",
      "Requirement already satisfied: openai>=1.0.0 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from tonic-validate<7.0.0,>=6.1.0->llama-index-evaluation-tonic-validate) (1.57.4)\n",
      "Requirement already satisfied: python-dotenv<2.0.0,>=1.0.1 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from tonic-validate<7.0.0,>=6.1.0->llama-index-evaluation-tonic-validate) (1.0.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from aiohttp<4.0.0,>=3.7.4.post0->aiobotocore==2.12.3->aiobotocore[boto3]==2.12.3->aioboto3<13.0.0,>=12.4.0->llama-index-evaluation-tonic-validate) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from aiohttp<4.0.0,>=3.7.4.post0->aiobotocore==2.12.3->aiobotocore[boto3]==2.12.3->aioboto3<13.0.0,>=12.4.0->llama-index-evaluation-tonic-validate) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from aiohttp<4.0.0,>=3.7.4.post0->aiobotocore==2.12.3->aiobotocore[boto3]==2.12.3->aioboto3<13.0.0,>=12.4.0->llama-index-evaluation-tonic-validate) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from aiohttp<4.0.0,>=3.7.4.post0->aiobotocore==2.12.3->aiobotocore[boto3]==2.12.3->aioboto3<13.0.0,>=12.4.0->llama-index-evaluation-tonic-validate) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from aiohttp<4.0.0,>=3.7.4.post0->aiobotocore==2.12.3->aiobotocore[boto3]==2.12.3->aioboto3<13.0.0,>=12.4.0->llama-index-evaluation-tonic-validate) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from aiohttp<4.0.0,>=3.7.4.post0->aiobotocore==2.12.3->aiobotocore[boto3]==2.12.3->aioboto3<13.0.0,>=12.4.0->llama-index-evaluation-tonic-validate) (1.17.1)\n",
      "Requirement already satisfied: google-ai-generativelanguage==0.6.4 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from google-generativeai<0.6.0,>=0.5.2->tonic-validate<7.0.0,>=6.1.0->llama-index-evaluation-tonic-validate) (0.6.4)\n",
      "Requirement already satisfied: google-api-core in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from google-generativeai<0.6.0,>=0.5.2->tonic-validate<7.0.0,>=6.1.0->llama-index-evaluation-tonic-validate) (2.23.0)\n",
      "Requirement already satisfied: google-api-python-client in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from google-generativeai<0.6.0,>=0.5.2->tonic-validate<7.0.0,>=6.1.0->llama-index-evaluation-tonic-validate) (2.151.0)\n",
      "Requirement already satisfied: google-auth>=2.15.0 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from google-generativeai<0.6.0,>=0.5.2->tonic-validate<7.0.0,>=6.1.0->llama-index-evaluation-tonic-validate) (2.36.0)\n",
      "Requirement already satisfied: protobuf in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from google-generativeai<0.6.0,>=0.5.2->tonic-validate<7.0.0,>=6.1.0->llama-index-evaluation-tonic-validate) (4.25.5)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from google-ai-generativelanguage==0.6.4->google-generativeai<0.6.0,>=0.5.2->tonic-validate<7.0.0,>=6.1.0->llama-index-evaluation-tonic-validate) (1.25.0)\n",
      "Requirement already satisfied: click in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from litellm<2.0.0,>=1.35.8->tonic-validate<7.0.0,>=6.1.0->llama-index-evaluation-tonic-validate) (8.1.7)\n",
      "Requirement already satisfied: importlib-metadata>=6.8.0 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from litellm<2.0.0,>=1.35.8->tonic-validate<7.0.0,>=6.1.0->llama-index-evaluation-tonic-validate) (8.4.0)\n",
      "Requirement already satisfied: jinja2<4.0.0,>=3.1.2 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from litellm<2.0.0,>=1.35.8->tonic-validate<7.0.0,>=6.1.0->llama-index-evaluation-tonic-validate) (3.1.4)\n",
      "Requirement already satisfied: jsonschema<5.0.0,>=4.22.0 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from litellm<2.0.0,>=1.35.8->tonic-validate<7.0.0,>=6.1.0->llama-index-evaluation-tonic-validate) (4.23.0)\n",
      "Requirement already satisfied: tokenizers in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from litellm<2.0.0,>=1.35.8->tonic-validate<7.0.0,>=6.1.0->llama-index-evaluation-tonic-validate) (0.20.3)\n",
      "Requirement already satisfied: anyio in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-evaluation-tonic-validate) (4.6.2.post1)\n",
      "Requirement already satisfied: certifi in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-evaluation-tonic-validate) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-evaluation-tonic-validate) (1.0.6)\n",
      "Requirement already satisfied: idna in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-evaluation-tonic-validate) (3.10)\n",
      "Requirement already satisfied: sniffio in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-evaluation-tonic-validate) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from httpcore==1.*->httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-evaluation-tonic-validate) (0.14.0)\n",
      "Requirement already satisfied: joblib in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-evaluation-tonic-validate) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-evaluation-tonic-validate) (2024.11.6)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from openai>=1.0.0->tonic-validate<7.0.0,>=6.1.0->llama-index-evaluation-tonic-validate) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from openai>=1.0.0->tonic-validate<7.0.0,>=6.1.0->llama-index-evaluation-tonic-validate) (0.7.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.0->llama-index-evaluation-tonic-validate) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.0->llama-index-evaluation-tonic-validate) (2.23.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.0->llama-index-evaluation-tonic-validate) (3.4.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.0->llama-index-evaluation-tonic-validate) (2.2.3)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.0->llama-index-evaluation-tonic-validate) (3.1.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from tqdm<5.0.0,>=4.66.1->llama-index-core<0.13.0,>=0.12.0->llama-index-evaluation-tonic-validate) (0.4.6)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from typing-inspect>=0.8.0->llama-index-core<0.13.0,>=0.12.0->llama-index-evaluation-tonic-validate) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from dataclasses-json->llama-index-core<0.13.0,>=0.12.0->llama-index-evaluation-tonic-validate) (3.23.1)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from boto3<1.34.70,>=1.34.41->aiobotocore[boto3]==2.12.3->aioboto3<13.0.0,>=12.4.0->llama-index-evaluation-tonic-validate) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from boto3<1.34.70,>=1.34.41->aiobotocore[boto3]==2.12.3->aioboto3<13.0.0,>=12.4.0->llama-index-evaluation-tonic-validate) (0.10.3)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from botocore<1.34.70,>=1.34.41->aiobotocore==2.12.3->aiobotocore[boto3]==2.12.3->aioboto3<13.0.0,>=12.4.0->llama-index-evaluation-tonic-validate) (2.8.2)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from google-api-core->google-generativeai<0.6.0,>=0.5.2->tonic-validate<7.0.0,>=6.1.0->llama-index-evaluation-tonic-validate) (1.63.2)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai<0.6.0,>=0.5.2->tonic-validate<7.0.0,>=6.1.0->llama-index-evaluation-tonic-validate) (5.5.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai<0.6.0,>=0.5.2->tonic-validate<7.0.0,>=6.1.0->llama-index-evaluation-tonic-validate) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai<0.6.0,>=0.5.2->tonic-validate<7.0.0,>=6.1.0->llama-index-evaluation-tonic-validate) (4.9)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from importlib-metadata>=6.8.0->litellm<2.0.0,>=1.35.8->tonic-validate<7.0.0,>=6.1.0->llama-index-evaluation-tonic-validate) (3.21.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from jinja2<4.0.0,>=3.1.2->litellm<2.0.0,>=1.35.8->tonic-validate<7.0.0,>=6.1.0->llama-index-evaluation-tonic-validate) (3.0.2)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from jsonschema<5.0.0,>=4.22.0->litellm<2.0.0,>=1.35.8->tonic-validate<7.0.0,>=6.1.0->llama-index-evaluation-tonic-validate) (2024.10.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from jsonschema<5.0.0,>=4.22.0->litellm<2.0.0,>=1.35.8->tonic-validate<7.0.0,>=6.1.0->llama-index-evaluation-tonic-validate) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from jsonschema<5.0.0,>=4.22.0->litellm<2.0.0,>=1.35.8->tonic-validate<7.0.0,>=6.1.0->llama-index-evaluation-tonic-validate) (0.21.0)\n",
      "Requirement already satisfied: packaging>=17.0 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.13.0,>=0.12.0->llama-index-evaluation-tonic-validate) (23.2)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from yarl<2.0,>=1.12.0->aiohttp<4.0.0,>=3.7.4.post0->aiobotocore==2.12.3->aiobotocore[boto3]==2.12.3->aioboto3<13.0.0,>=12.4.0->llama-index-evaluation-tonic-validate) (0.2.0)\n",
      "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from google-api-python-client->google-generativeai<0.6.0,>=0.5.2->tonic-validate<7.0.0,>=6.1.0->llama-index-evaluation-tonic-validate) (0.22.0)\n",
      "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from google-api-python-client->google-generativeai<0.6.0,>=0.5.2->tonic-validate<7.0.0,>=6.1.0->llama-index-evaluation-tonic-validate) (0.2.0)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from google-api-python-client->google-generativeai<0.6.0,>=0.5.2->tonic-validate<7.0.0,>=6.1.0->llama-index-evaluation-tonic-validate) (4.1.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from tokenizers->litellm<2.0.0,>=1.35.8->tonic-validate<7.0.0,>=6.1.0->llama-index-evaluation-tonic-validate) (0.23.5)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.4->google-generativeai<0.6.0,>=0.5.2->tonic-validate<7.0.0,>=6.1.0->llama-index-evaluation-tonic-validate) (1.67.1)\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.4->google-generativeai<0.6.0,>=0.5.2->tonic-validate<7.0.0,>=6.1.0->llama-index-evaluation-tonic-validate) (1.62.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client->google-generativeai<0.6.0,>=0.5.2->tonic-validate<7.0.0,>=6.1.0->llama-index-evaluation-tonic-validate) (3.2.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm<2.0.0,>=1.35.8->tonic-validate<7.0.0,>=6.1.0->llama-index-evaluation-tonic-validate) (3.16.1)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai<0.6.0,>=0.5.2->tonic-validate<7.0.0,>=6.1.0->llama-index-evaluation-tonic-validate) (0.6.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.34.70,>=1.34.41->aiobotocore==2.12.3->aiobotocore[boto3]==2.12.3->aioboto3<13.0.0,>=12.4.0->llama-index-evaluation-tonic-validate) (1.16.0)\n",
      "Requirement already satisfied: tvallogging in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (1.0.0)\n",
      "Requirement already satisfied: tvalmetrics<2.0.0,>=1.0.0 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from tvallogging) (1.0.2)\n",
      "Requirement already satisfied: openai>=1.0.0 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from tvalmetrics<2.0.0,>=1.0.0->tvallogging) (1.57.4)\n",
      "Requirement already satisfied: pandas>=1.2.3 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from tvalmetrics<2.0.0,>=1.0.0->tvallogging) (2.2.3)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from openai>=1.0.0->tvalmetrics<2.0.0,>=1.0.0->tvallogging) (4.6.2.post1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from openai>=1.0.0->tvalmetrics<2.0.0,>=1.0.0->tvallogging) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from openai>=1.0.0->tvalmetrics<2.0.0,>=1.0.0->tvallogging) (0.27.2)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from openai>=1.0.0->tvalmetrics<2.0.0,>=1.0.0->tvallogging) (0.7.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from openai>=1.0.0->tvalmetrics<2.0.0,>=1.0.0->tvallogging) (2.9.2)\n",
      "Requirement already satisfied: sniffio in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from openai>=1.0.0->tvalmetrics<2.0.0,>=1.0.0->tvallogging) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from openai>=1.0.0->tvalmetrics<2.0.0,>=1.0.0->tvallogging) (4.67.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from openai>=1.0.0->tvalmetrics<2.0.0,>=1.0.0->tvallogging) (4.11.0)\n",
      "Requirement already satisfied: numpy>=1.23.2 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from pandas>=1.2.3->tvalmetrics<2.0.0,>=1.0.0->tvallogging) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from pandas>=1.2.3->tvalmetrics<2.0.0,>=1.0.0->tvallogging) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from pandas>=1.2.3->tvalmetrics<2.0.0,>=1.0.0->tvallogging) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from pandas>=1.2.3->tvalmetrics<2.0.0,>=1.0.0->tvallogging) (2024.2)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from anyio<5,>=3.5.0->openai>=1.0.0->tvalmetrics<2.0.0,>=1.0.0->tvallogging) (3.10)\n",
      "Requirement already satisfied: certifi in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from httpx<1,>=0.23.0->openai>=1.0.0->tvalmetrics<2.0.0,>=1.0.0->tvallogging) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from httpx<1,>=0.23.0->openai>=1.0.0->tvalmetrics<2.0.0,>=1.0.0->tvallogging) (1.0.6)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai>=1.0.0->tvalmetrics<2.0.0,>=1.0.0->tvallogging) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from pydantic<3,>=1.9.0->openai>=1.0.0->tvalmetrics<2.0.0,>=1.0.0->tvallogging) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from pydantic<3,>=1.9.0->openai>=1.0.0->tvalmetrics<2.0.0,>=1.0.0->tvallogging) (2.23.4)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from python-dateutil>=2.8.2->pandas>=1.2.3->tvalmetrics<2.0.0,>=1.0.0->tvallogging) (1.16.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\muthu\\.conda\\envs\\llamaindex\\lib\\site-packages (from tqdm>4->openai>=1.0.0->tvalmetrics<2.0.0,>=1.0.0->tvallogging) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "!pip install llama-index\n",
    "%pip install tonic-validate\n",
    "%pip install llama-index-evaluation-tonic-validate\n",
    "%pip install tvallogging\n",
    "\n",
    "\n",
    "import logging\n",
    "import sys\n",
    "\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.ERROR)\n",
    "logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))\n",
    "\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.openai import OpenAI\n",
    "\n",
    "import getpass\n",
    "import os\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"open ai api key: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "os.environ[\"TONIC_VALIDATE_API_KEY\"] = getpass.getpass(\"Tonic Validate api key: \")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader\n",
    "\n",
    "documents = SimpleDirectoryReader(\"./paul_graham_essays\").load_data()\n",
    "index = VectorStoreIndex.from_documents(documents)\n",
    "query_engine = index.as_query_engine()\n",
    "\n",
    "# Gets the response from llama index\n",
    "def get_llama_response(prompt):\n",
    "    response = query_engine.query(prompt)\n",
    "    context = [x.text for x in response.source_nodes]\n",
    "    return {\n",
    "        \"llm_answer\": response.response,\n",
    "        \"llm_context_list\": context\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from tonic_validate import Benchmark\n",
    "\n",
    "import json\n",
    "qa_pairs = []\n",
    "with open(\"question_and_answer_list.json\", \"r\") as qa_file:\n",
    "    qa_pairs = json.load(qa_file)[:10]\n",
    "\n",
    "question_list = [qa_pair['question'] for qa_pair in qa_pairs]\n",
    "answer_list = [qa_pair['answer'] for qa_pair in qa_pairs]\n",
    "\n",
    "benchmark = Benchmark(questions=question_list, answers=answer_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tonic_validate import ValidateApi\n",
    "validate_api = ValidateApi(\"api-key-here\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrieving responses:   0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrieving responses:  10%|█         | 1/10 [00:02<00:20,  2.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrieving responses:  20%|██        | 2/10 [00:03<00:12,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrieving responses:  30%|███       | 3/10 [00:04<00:10,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrieving responses:  40%|████      | 4/10 [00:06<00:08,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrieving responses:  50%|█████     | 5/10 [00:07<00:07,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrieving responses:  60%|██████    | 6/10 [00:09<00:06,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrieving responses:  70%|███████   | 7/10 [00:10<00:04,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrieving responses:  80%|████████  | 8/10 [00:12<00:03,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrieving responses:  90%|█████████ | 9/10 [00:14<00:01,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrieving responses: 100%|██████████| 10/10 [00:16<00:00,  1.62s/it]\n",
      "Scoring responses:   0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 1.338000 seconds\n",
      "Retrying request to /chat/completions in 1.338000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.846000 seconds\n",
      "Retrying request to /chat/completions in 0.846000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 2.696000 seconds\n",
      "Retrying request to /chat/completions in 2.696000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 1.996000 seconds\n",
      "Retrying request to /chat/completions in 1.996000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 2.150000 seconds\n",
      "Retrying request to /chat/completions in 2.150000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 1.966000 seconds\n",
      "Retrying request to /chat/completions in 1.966000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 2.080000 seconds\n",
      "Retrying request to /chat/completions in 2.080000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 1.980000 seconds\n",
      "Retrying request to /chat/completions in 1.980000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.652000 seconds\n",
      "Retrying request to /chat/completions in 0.652000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.600000 seconds\n",
      "Retrying request to /chat/completions in 0.600000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.350000 seconds\n",
      "Retrying request to /chat/completions in 0.350000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 1.190000 seconds\n",
      "Retrying request to /chat/completions in 1.190000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 1.132000 seconds\n",
      "Retrying request to /chat/completions in 1.132000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 1.140000 seconds\n",
      "Retrying request to /chat/completions in 1.140000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 1.516000 seconds\n",
      "Retrying request to /chat/completions in 1.516000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 1.516000 seconds\n",
      "Retrying request to /chat/completions in 1.516000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 1.514000 seconds\n",
      "Retrying request to /chat/completions in 1.514000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 2.200000 seconds\n",
      "Retrying request to /chat/completions in 2.200000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.932000 seconds\n",
      "Retrying request to /chat/completions in 0.932000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 1.086000 seconds\n",
      "Retrying request to /chat/completions in 1.086000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.880000 seconds\n",
      "Retrying request to /chat/completions in 0.880000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 2.248000 seconds\n",
      "Retrying request to /chat/completions in 2.248000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 4.270000 seconds\n",
      "Retrying request to /chat/completions in 4.270000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 1.164000 seconds\n",
      "Retrying request to /chat/completions in 1.164000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 1.190000 seconds\n",
      "Retrying request to /chat/completions in 1.190000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 2.786000 seconds\n",
      "Retrying request to /chat/completions in 2.786000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.776000 seconds\n",
      "Retrying request to /chat/completions in 0.776000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.792000 seconds\n",
      "Retrying request to /chat/completions in 0.792000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.782000 seconds\n",
      "Retrying request to /chat/completions in 0.782000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.720000 seconds\n",
      "Retrying request to /chat/completions in 0.720000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.792000 seconds\n",
      "Retrying request to /chat/completions in 0.792000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 2.370000 seconds\n",
      "Retrying request to /chat/completions in 2.370000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 2.352000 seconds\n",
      "Retrying request to /chat/completions in 2.352000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 2.330000 seconds\n",
      "Retrying request to /chat/completions in 2.330000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 2.340000 seconds\n",
      "Retrying request to /chat/completions in 2.340000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 2.068000 seconds\n",
      "Retrying request to /chat/completions in 2.068000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 2.252000 seconds\n",
      "Retrying request to /chat/completions in 2.252000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 2.240000 seconds\n",
      "Retrying request to /chat/completions in 2.240000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 2.080000 seconds\n",
      "Retrying request to /chat/completions in 2.080000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 4.264000 seconds\n",
      "Retrying request to /chat/completions in 4.264000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 2.052000 seconds\n",
      "Retrying request to /chat/completions in 2.052000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 2.806000 seconds\n",
      "Retrying request to /chat/completions in 2.806000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 2.380000 seconds\n",
      "Retrying request to /chat/completions in 2.380000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 2.300000 seconds\n",
      "Retrying request to /chat/completions in 2.300000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 2.244000 seconds\n",
      "Retrying request to /chat/completions in 2.244000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 2.230000 seconds\n",
      "Retrying request to /chat/completions in 2.230000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 3.532000 seconds\n",
      "Retrying request to /chat/completions in 3.532000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 3.530000 seconds\n",
      "Retrying request to /chat/completions in 3.530000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 2.264000 seconds\n",
      "Retrying request to /chat/completions in 2.264000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 2.424000 seconds\n",
      "Retrying request to /chat/completions in 2.424000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 2.260000 seconds\n",
      "Retrying request to /chat/completions in 2.260000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 2.400000 seconds\n",
      "Retrying request to /chat/completions in 2.400000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 2.390000 seconds\n",
      "Retrying request to /chat/completions in 2.390000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 2.440000 seconds\n",
      "Retrying request to /chat/completions in 2.440000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 2.434000 seconds\n",
      "Retrying request to /chat/completions in 2.434000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 2.456000 seconds\n",
      "Retrying request to /chat/completions in 2.456000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 4.114000 seconds\n",
      "Retrying request to /chat/completions in 4.114000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 3.978000 seconds\n",
      "Retrying request to /chat/completions in 3.978000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 3.254000 seconds\n",
      "Retrying request to /chat/completions in 3.254000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 2.764000 seconds\n",
      "Retrying request to /chat/completions in 2.764000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.538000 seconds\n",
      "Retrying request to /chat/completions in 0.538000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 4.046000 seconds\n",
      "Retrying request to /chat/completions in 4.046000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 1.188000 seconds\n",
      "Retrying request to /chat/completions in 1.188000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 2.456000 seconds\n",
      "Retrying request to /chat/completions in 2.456000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 2.142000 seconds\n",
      "Retrying request to /chat/completions in 2.142000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 2.224000 seconds\n",
      "Retrying request to /chat/completions in 2.224000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.062000 seconds\n",
      "Retrying request to /chat/completions in 0.062000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 1.872000 seconds\n",
      "Retrying request to /chat/completions in 1.872000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 1.890000 seconds\n",
      "Retrying request to /chat/completions in 1.890000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 1.989000 seconds\n",
      "Retrying request to /chat/completions in 1.989000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 2.384000 seconds\n",
      "Retrying request to /chat/completions in 2.384000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 1.992000 seconds\n",
      "Retrying request to /chat/completions in 1.992000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 2.280000 seconds\n",
      "Retrying request to /chat/completions in 2.280000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 2.304000 seconds\n",
      "Retrying request to /chat/completions in 2.304000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 1.826000 seconds\n",
      "Retrying request to /chat/completions in 1.826000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 2.510000 seconds\n",
      "Retrying request to /chat/completions in 2.510000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 3.775000 seconds\n",
      "Retrying request to /chat/completions in 3.775000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 3.712000 seconds\n",
      "Retrying request to /chat/completions in 3.712000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 2.488000 seconds\n",
      "Retrying request to /chat/completions in 2.488000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 2.620000 seconds\n",
      "Retrying request to /chat/completions in 2.620000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 2.648000 seconds\n",
      "Retrying request to /chat/completions in 2.648000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 1.452000 seconds\n",
      "Retrying request to /chat/completions in 1.452000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 1.220000 seconds\n",
      "Retrying request to /chat/completions in 1.220000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.202000 seconds\n",
      "Retrying request to /chat/completions in 0.202000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring responses:  10%|█         | 1/10 [00:34<05:10, 34.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 2.834000 seconds\n",
      "Retrying request to /chat/completions in 2.834000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 2.860000 seconds\n",
      "Retrying request to /chat/completions in 2.860000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 2.810000 seconds\n",
      "Retrying request to /chat/completions in 2.810000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 2.858000 seconds\n",
      "Retrying request to /chat/completions in 2.858000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 2.806000 seconds\n",
      "Retrying request to /chat/completions in 2.806000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 2.854000 seconds\n",
      "Retrying request to /chat/completions in 2.854000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 1.506000 seconds\n",
      "Retrying request to /chat/completions in 1.506000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.738000 seconds\n",
      "Retrying request to /chat/completions in 0.738000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 3.332000 seconds\n",
      "Retrying request to /chat/completions in 3.332000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 2.060000 seconds\n",
      "Retrying request to /chat/completions in 2.060000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 2.808000 seconds\n",
      "Retrying request to /chat/completions in 2.808000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 1.536000 seconds\n",
      "Retrying request to /chat/completions in 1.536000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 4.284000 seconds\n",
      "Retrying request to /chat/completions in 4.284000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 4.156000 seconds\n",
      "Retrying request to /chat/completions in 4.156000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 3.368000 seconds\n",
      "Retrying request to /chat/completions in 3.368000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 2.052000 seconds\n",
      "Retrying request to /chat/completions in 2.052000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 2.830000 seconds\n",
      "Retrying request to /chat/completions in 2.830000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 2.846000 seconds\n",
      "Retrying request to /chat/completions in 2.846000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 1.602000 seconds\n",
      "Retrying request to /chat/completions in 1.602000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 1.308000 seconds\n",
      "Retrying request to /chat/completions in 1.308000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring responses:  20%|██        | 2/10 [00:43<02:38, 19.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 2.868000 seconds\n",
      "Retrying request to /chat/completions in 2.868000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 2.854000 seconds\n",
      "Retrying request to /chat/completions in 2.854000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 2.750000 seconds\n",
      "Retrying request to /chat/completions in 2.750000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 2.196000 seconds\n",
      "Retrying request to /chat/completions in 2.196000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 2.182000 seconds\n",
      "Retrying request to /chat/completions in 2.182000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.408000 seconds\n",
      "Retrying request to /chat/completions in 0.408000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 4.396000 seconds\n",
      "Retrying request to /chat/completions in 4.396000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 2.826000 seconds\n",
      "Retrying request to /chat/completions in 2.826000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 4.008000 seconds\n",
      "Retrying request to /chat/completions in 4.008000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 3.202000 seconds\n",
      "Retrying request to /chat/completions in 3.202000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 3.054000 seconds\n",
      "Retrying request to /chat/completions in 3.054000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 2.796000 seconds\n",
      "Retrying request to /chat/completions in 2.796000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 3.010000 seconds\n",
      "Retrying request to /chat/completions in 3.010000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.386000 seconds\n",
      "Retrying request to /chat/completions in 0.386000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 4.362000 seconds\n",
      "Retrying request to /chat/completions in 4.362000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 4.384000 seconds\n",
      "Retrying request to /chat/completions in 4.384000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 4.358000 seconds\n",
      "Retrying request to /chat/completions in 4.358000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 4.268000 seconds\n",
      "Retrying request to /chat/completions in 4.268000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 3.770000 seconds\n",
      "Retrying request to /chat/completions in 3.770000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 3.966000 seconds\n",
      "Retrying request to /chat/completions in 3.966000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring responses:  30%|███       | 3/10 [00:56<01:54, 16.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 2.392000 seconds\n",
      "Retrying request to /chat/completions in 2.392000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 3.838000 seconds\n",
      "Retrying request to /chat/completions in 3.838000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 2.700000 seconds\n",
      "Retrying request to /chat/completions in 2.700000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 3.050000 seconds\n",
      "Retrying request to /chat/completions in 3.050000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring responses:  40%|████      | 4/10 [01:08<01:29, 14.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 2.728000 seconds\n",
      "Retrying request to /chat/completions in 2.728000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 1.252000 seconds\n",
      "Retrying request to /chat/completions in 1.252000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.968000 seconds\n",
      "Retrying request to /chat/completions in 0.968000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 4.358000 seconds\n",
      "Retrying request to /chat/completions in 4.358000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 4.404000 seconds\n",
      "Retrying request to /chat/completions in 4.404000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 2.720000 seconds\n",
      "Retrying request to /chat/completions in 2.720000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 2.786000 seconds\n",
      "Retrying request to /chat/completions in 2.786000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 2.800000 seconds\n",
      "Retrying request to /chat/completions in 2.800000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 2.820000 seconds\n",
      "Retrying request to /chat/completions in 2.820000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 1.650000 seconds\n",
      "Retrying request to /chat/completions in 1.650000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 4.432000 seconds\n",
      "Retrying request to /chat/completions in 4.432000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 4.228000 seconds\n",
      "Retrying request to /chat/completions in 4.228000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring responses:  50%|█████     | 5/10 [01:24<01:16, 15.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 2.596000 seconds\n",
      "Retrying request to /chat/completions in 2.596000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring responses:  60%|██████    | 6/10 [01:28<00:45, 11.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 1.218000 seconds\n",
      "Retrying request to /chat/completions in 1.218000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 4.284000 seconds\n",
      "Retrying request to /chat/completions in 4.284000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 2.940000 seconds\n",
      "Retrying request to /chat/completions in 2.940000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring responses:  70%|███████   | 7/10 [01:45<00:39, 13.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 3.136000 seconds\n",
      "Retrying request to /chat/completions in 3.136000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 2.940000 seconds\n",
      "Retrying request to /chat/completions in 2.940000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 2.854000 seconds\n",
      "Retrying request to /chat/completions in 2.854000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring responses:  80%|████████  | 8/10 [01:57<00:25, 12.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring responses:  90%|█████████ | 9/10 [02:08<00:12, 12.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 2.158000 seconds\n",
      "Retrying request to /chat/completions in 2.158000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 2.892000 seconds\n",
      "Retrying request to /chat/completions in 2.892000 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring responses: 100%|██████████| 10/10 [02:21<00:00, 14.19s/it]\n"
     ]
    }
   ],
   "source": [
    "from tonic_validate import ValidateScorer, ValidateApi\n",
    "from tonic_validate.classes.benchmark import BenchmarkItem\n",
    "\n",
    "# Score the responses\n",
    "scorer = ValidateScorer()\n",
    "run = scorer.score(benchmark, get_llama_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0495d51b-bd75-43c9-8f12-04a728aca0e1'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tonic_validate import ValidateApi\n",
    "# Upload the run\n",
    "validate_api = ValidateApi(\"HRnZlKU7z9is8bleVzCtMC67zg9_QFcxRumgyTGD6k8\")\n",
    "validate_api.upload_run(\"a0d47f31-518d-476a-80e5-5b9e74c1f739\", run)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llamaindex",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
