{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install llama-index-llms-openai pandas[jinja2] spacy\n",
    "\n",
    "import logging\n",
    "import sys\n",
    "\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.ERROR)\n",
    "logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))\n",
    "\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from llama_index.core import Settings\n",
    "from llama_index.llms.ollama import Ollama\n",
    "from llama_index.embeddings.ollama import OllamaEmbedding\n",
    "\n",
    "# Configure Ollama LLM\n",
    "ollama_llm = Ollama(\n",
    "    model=\"llama3.2:latest\",\n",
    "    base_url=\"http://localhost:11434\",\n",
    "    temperature=0.1\n",
    ")\n",
    "\n",
    "# Configure embedding model\n",
    "ollama_embedding = OllamaEmbedding(\n",
    "    model_name=\"nomic-embed-text:latest\",\n",
    "    base_url=\"http://localhost:11434\",\n",
    "    ollama_additional_kwargs={\"mirostat\": 0}\n",
    ")\n",
    "\n",
    "Settings.llm = ollama_llm\n",
    "Settings.embed_model = ollama_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import (\n",
    "    VectorStoreIndex,\n",
    "    SimpleDirectoryReader,\n",
    "    Response,\n",
    ")\n",
    "from llama_index.core.evaluation import RelevancyEvaluator\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option(\"display.max_colwidth\", 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator_ollama = RelevancyEvaluator(llm=ollama_llm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = SimpleDirectoryReader(\"./test_wiki_data\").load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create vector index\n",
    "splitter = SentenceSplitter(chunk_size=256)\n",
    "vector_index = VectorStoreIndex.from_documents(\n",
    "    documents, transformations=[splitter]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.evaluation import EvaluationResult\n",
    "\n",
    "\n",
    "# define jupyter display function\n",
    "def display_eval_df(\n",
    "    query: str, response: Response, eval_result: EvaluationResult\n",
    ") -> None:\n",
    "    eval_df = pd.DataFrame(\n",
    "        {\n",
    "            \"Query\": query,\n",
    "            \"Response\": str(response),\n",
    "            \"Source\": response.source_nodes[0].node.text[:1000] + \"...\",\n",
    "            \"Evaluation Result\": \"Pass\" if eval_result.passing else \"Fail\",\n",
    "            \"Reasoning\": eval_result.feedback,\n",
    "        },\n",
    "        index=[0],\n",
    "    )\n",
    "    eval_df = eval_df.style.set_properties(\n",
    "        **{\n",
    "            \"inline-size\": \"600px\",\n",
    "            \"overflow-wrap\": \"break-word\",\n",
    "        },\n",
    "        subset=[\"Response\", \"Source\"]\n",
    "    )\n",
    "    display(eval_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_str = (\n",
    "    \"What battles took place in New York City in the American Revolution?\"\n",
    ")\n",
    "query_engine = vector_index.as_query_engine()\n",
    "response_vector = query_engine.query(query_str)\n",
    "eval_result = evaluator_ollama.evaluate_response(\n",
    "    query=query_str, response=response_vector\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_eval_df(query_str, response_vector, eval_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_str = \"What are the airports in New York City?\"\n",
    "query_engine = vector_index.as_query_engine()\n",
    "response_vector = query_engine.query(query_str)\n",
    "eval_result = evaluator_ollama.evaluate_response(\n",
    "    query=query_str, response=response_vector\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_eval_df(query_str, response_vector, eval_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "\n",
    "# define jupyter display function\n",
    "def display_eval_sources(\n",
    "    query: str, response: Response, eval_result: List[str]\n",
    ") -> None:\n",
    "    sources = [s.node.get_text() for s in response.source_nodes]\n",
    "    eval_df = pd.DataFrame(\n",
    "        {\n",
    "            \"Source\": sources,\n",
    "            \"Eval Result\": eval_result,\n",
    "        },\n",
    "    )\n",
    "    eval_df.style.set_caption(query)\n",
    "    eval_df = eval_df.style.set_properties(\n",
    "        **{\n",
    "            \"inline-size\": \"600px\",\n",
    "            \"overflow-wrap\": \"break-word\",\n",
    "        },\n",
    "        subset=[\"Source\"]\n",
    "    )\n",
    "\n",
    "    display(eval_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: you can set response_mode=\"no_text\" to get just the sources\n",
    "query_str = \"What are the airports in New York City?\"\n",
    "query_engine = vector_index.as_query_engine(\n",
    "    similarity_top_k=3, response_mode=\"no_text\"\n",
    ")\n",
    "response_vector = query_engine.query(query_str)\n",
    "eval_source_result_full = [\n",
    "    evaluator_ollama.evaluate(\n",
    "        query=query_str,\n",
    "        response=response_vector.response,\n",
    "        contexts=[source_node.get_content()],\n",
    "    )\n",
    "    for source_node in response_vector.source_nodes\n",
    "]\n",
    "eval_source_result = [\n",
    "    \"Pass\" if result.passing else \"Fail\" for result in eval_source_result_full\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_eval_sources(query_str, response_vector, eval_source_result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llamaindex",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
