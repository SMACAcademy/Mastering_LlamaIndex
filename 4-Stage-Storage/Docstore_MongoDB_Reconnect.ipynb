{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker run --name mongodb -d -p 27017:27017 mongo:latest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker ps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install llama-index-storage-docstore-mongodb\n",
    "%pip install llama-index-storage-index-store-mongodb\n",
    "%pip install llama-index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "from llama_index.core import SimpleDirectoryReader, StorageContext\n",
    "from llama_index.core import VectorStoreIndex, SimpleKeywordTableIndex, SummaryIndex\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "from llama_index.storage.docstore.mongodb import MongoDocumentStore\n",
    "from llama_index.storage.index_store.mongodb import MongoIndexStore\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "# MongoDB connection URI\n",
    "MONGO_URI = \"mongodb://localhost:27017\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"open ai api key: \")\n",
    "from llama_index.core import Settings\n",
    "from llama_index.llms.ollama import  Ollama\n",
    "Settings.llm = Ollama(model='llama3.2:latest', base_url='http://localhost:11434',temperature=0.1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.embeddings.ollama import OllamaEmbedding\n",
    "\n",
    "ollama_embedding = OllamaEmbedding(\n",
    "    model_name=\"nomic-embed-text:latest\",  # Replace with your desired model\n",
    "    base_url=\"http://localhost:11434\",  # Ensure Ollama is running at this endpoint\n",
    "    ollama_additional_kwargs={\"mirostat\": 0} #Mirostat is a technique for controlling perplexity and balancing the text generation process in large language models (LLMs).\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "# Load the saved index IDs\n",
    "with open(\"mongodb_index_ids.json\", \"r\") as f:\n",
    "    index_ids = json.load(f)\n",
    "\n",
    "summary_id = index_ids[\"summary_id\"]\n",
    "vector_id = index_ids[\"vector_id\"]\n",
    "keyword_id = index_ids[\"keyword_id\"]\n",
    "\n",
    "# Re-create storage context\n",
    "storage_context = StorageContext.from_defaults(\n",
    "    docstore=MongoDocumentStore.from_uri(uri=MONGO_URI),\n",
    "    index_store=MongoIndexStore.from_uri(uri=MONGO_URI),\n",
    ")\n",
    "\n",
    "# Reload indices\n",
    "summary_index = load_index_from_storage(storage_context=storage_context, index_id=summary_id)\n",
    "vector_index = load_index_from_storage(storage_context=storage_context, index_id=vector_id, embed_model=ollama_embedding)\n",
    "keyword_table_index = load_index_from_storage(storage_context=storage_context, index_id=keyword_id)\n",
    "\n",
    "print(\"Indices reloaded successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = summary_index.storage_context.docstore.docs.values()\n",
    "for node in nodes:\n",
    "    print(f\"Node Text: {node.text}\")\n",
    "    print(f\"Node Metadata: {node.extra_info}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query Summary Index\n",
    "query_engine = summary_index.as_query_engine()\n",
    "summary_response = query_engine.query(\"What is a summary of this document?\")\n",
    "print(summary_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query Summary Index\n",
    "query_engine = summary_index.as_query_engine()\n",
    "summary_response = query_engine.query(\"What is a summary of this document?\")\n",
    "print(summary_response)\n",
    "\n",
    "# Query Vector Index\n",
    "query_engine = vector_index.as_query_engine()\n",
    "vector_response = query_engine.query(\"What did the author do growing up?\")\n",
    "print(vector_response)\n",
    "\n",
    "# Query Keyword Table Index\n",
    "query_engine = keyword_table_index.as_query_engine()\n",
    "keyword_response = query_engine.query(\"What did the author do after his time at YC?\")\n",
    "print(keyword_response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**`Final Response:`** The document appears to be a collection of anecdotes and reflections from the writer's experiences in the startup world, particularly at Viaweb and Y Combinator. The writer shares stories about the challenges they faced, such as navigating the complexities of online publishing, dealing with criticism for their technical choices, and adjusting to new realities after being acquired by Yahoo.\n",
       "\n",
       "The writer also discusses how these experiences made them realize that they needed to make a change and eventually left Y Combinator. Overall, the document provides a glimpse into the writer's personal struggles and growth as an entrepreneur, highlighting the challenges and lessons learned from their time in the startup world."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**`Final Response:`** Empty Response"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**`Final Response:`** The author shifted his focus to other pursuits after leaving YC. He began exploring painting as a new creative outlet, allowing him to dedicate himself fully to it. This endeavor provided an opportunity for personal growth and self-discovery. Although he initially showed promise, the author eventually lost interest in painting and redirected his attention towards writing essays once more. Additionally, he delved into Lisp programming, a language that had long fascinated him."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from llama_index.core.response.notebook_utils import display_response\n",
    "\n",
    "display_response(summary_response)\n",
    "display_response(vector_response)\n",
    "display_response(keyword_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**`Final Response:`** The author shifted his focus to other pursuits after leaving YC. He began exploring painting as a new creative outlet, allowing him to dedicate himself fully to it. This endeavor provided an opportunity for personal growth and self-discovery. Although he initially showed promise, the author eventually lost interest in painting and redirected his attention towards writing essays once more. Additionally, he delved into Lisp programming, a language that had long fascinated him."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llamaindex",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
