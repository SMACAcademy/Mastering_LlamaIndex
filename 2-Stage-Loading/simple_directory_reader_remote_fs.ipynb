{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/run-llama/llama_index/blob/main/docs/docs/examples/data_connectors/simple_directory_reader.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Directory Reader over a Remote FileSystem"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `SimpleDirectoryReader` is the most commonly used data connector that _just works_.  \n",
    "By default, it can be used to parse a variety of file-types on your local filesystem into a list of `Document` objects.\n",
    "Additionaly, it can also be configured to read from a remote filesystem just as easily! This is made possible through the [`fsspec`](https://filesystem-spec.readthedocs.io/en/latest/index.html) protocol.\n",
    "\n",
    "This notebook will take you through an example of using `SimpleDirectoryReader` to load documents from an S3 bucket. You can either run this against an actual S3 bucket, or a locally emulated S3 bucket via [LocalStack](https://www.localstack.cloud/)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Started"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you're opening this Notebook on colab, you will probably need to install LlamaIndex ðŸ¦™."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install llama-index s3fs boto3 "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this in Windows to download the file again\n",
    "!wsl mkdir -p 'data/paul_graham/'\n",
    "!wsl wget 'https://raw.githubusercontent.com/run-llama/llama_index/main/docs/docs/examples/data/paul_graham/paul_graham_essay.txt' -O 'data/paul_graham/paul_graham_essay1.txt'\n",
    "!wsl wget 'https://raw.githubusercontent.com/run-llama/llama_index/main/docs/docs/examples/data/paul_graham/paul_graham_essay.txt' -O 'data/paul_graham/paul_graham_essay2.txt'\n",
    "!wsl wget 'https://raw.githubusercontent.com/run-llama/llama_index/main/docs/docs/examples/data/paul_graham/paul_graham_essay.txt' -O 'data/paul_graham/paul_graham_essay3.txt'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p 'data/paul_graham/'\n",
    "!wget 'https://raw.githubusercontent.com/run-llama/llama_index/main/docs/docs/examples/data/paul_graham/paul_graham_essay.txt' -O 'data/paul_graham/paul_graham_essay1.txt'\n",
    "!wget 'https://raw.githubusercontent.com/run-llama/llama_index/main/docs/docs/examples/data/paul_graham/paul_graham_essay.txt' -O 'data/paul_graham/paul_graham_essay2.txt'\n",
    "!wget 'https://raw.githubusercontent.com/run-llama/llama_index/main/docs/docs/examples/data/paul_graham/paul_graham_essay.txt' -O 'data/paul_graham/paul_graham_essay3.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker run -d -p 4566:4566 -p 4571:4571 localstack/localstack\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a test-bucket in S3\n",
    "import boto3\n",
    "\n",
    "endpoint_url = (\n",
    "    \"http://localhost:4566\"  # use this line if you are using S3 via localstack\n",
    ")\n",
    "# endpoint_url = None  # use this line if you are using real AWS S3\n",
    "bucket_name = \"llama-index-test-bucket\"\n",
    "#s3 = boto3.resource(\"s3\", endpoint_url=endpoint_url)\n",
    "# Set up boto3 resource with dummy credentials\n",
    "s3 = boto3.resource(\n",
    "    \"s3\",\n",
    "    endpoint_url=endpoint_url,\n",
    "    aws_access_key_id=\"dummy_access_key\",\n",
    "    aws_secret_access_key=\"dummy_secret_key\",\n",
    ")\n",
    "s3.create_bucket(Bucket=bucket_name)\n",
    "bucket = s3.Bucket(bucket_name)\n",
    "# put the paul graham essays in the test-bucket in various subdirectories\n",
    "bucket.upload_file(\n",
    "    \"data/paul_graham/paul_graham_essay1.txt\", \"essays/paul_graham_essay1.txt\"\n",
    ")\n",
    "bucket.upload_file(\n",
    "    \"data/paul_graham/paul_graham_essay2.txt\",\n",
    "    \"essays/more_essays/paul_graham_essay2.txt\",\n",
    ")\n",
    "bucket.upload_file(\n",
    "    \"data/paul_graham/paul_graham_essay3.txt\",\n",
    "    \"essays/even_more_essays/paul_graham_essay3.txt\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import SimpleDirectoryReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the filesystem using s3fs\n",
    "from s3fs import S3FileSystem\n",
    "\n",
    "s3_fs = S3FileSystem(anon=False,\n",
    "                    key=\"dummy_access_key\",  # Dummy access key for LocalStack\n",
    "                    secret=\"dummy_secret_key\",  # Dummy secret key for LocalStack\n",
    "                    endpoint_url=endpoint_url)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load specific files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = SimpleDirectoryReader(\n",
    "    input_dir=bucket_name,\n",
    "    fs=s3_fs,\n",
    "    recursive=True,  # recursively searches all subdirectories\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = reader.load_data()\n",
    "print(f\"Loaded {len(docs)} docs\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load all (top-level) files from directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = SimpleDirectoryReader(input_dir=\"./data/paul_graham/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = reader.load_data()\n",
    "print(f\"Loaded {len(docs)} docs\")\n",
    "\n",
    "# show the metadata of each document\n",
    "for idx, doc in enumerate(docs):\n",
    "    print(f\"{idx} - {doc.metadata}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = reader.load_data()\n",
    "print(f\"Loaded {len(docs)} docs\")\n",
    "\n",
    "# show the metadata of each document\n",
    "for idx, doc in enumerate(docs):\n",
    "    print(f\"{idx} - {doc.metadata}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an iterator to load files and process them as they load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = SimpleDirectoryReader(\n",
    "    input_dir=bucket_name,\n",
    "    fs=s3_fs,\n",
    "    recursive=True,\n",
    ")\n",
    "\n",
    "all_docs = []\n",
    "for docs in reader.iter_data():\n",
    "    for doc in docs:\n",
    "        # do something with the doc\n",
    "        doc.text = doc.text.upper()\n",
    "        all_docs.append(doc)\n",
    "\n",
    "print(len(all_docs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exclude specific patterns on the remote FS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = SimpleDirectoryReader(\n",
    "    input_dir=bucket_name,\n",
    "    fs=s3_fs,\n",
    "    recursive=True,\n",
    "    exclude=[\"essays/more_essays/*\"],\n",
    ")\n",
    "\n",
    "all_docs = []\n",
    "for docs in reader.iter_data():\n",
    "    for doc in docs:\n",
    "        # do something with the doc\n",
    "        doc.text = doc.text.upper()\n",
    "        all_docs.append(doc)\n",
    "\n",
    "print(len(all_docs))\n",
    "all_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Async execution is available through `aload_data`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "reader = SimpleDirectoryReader(\n",
    "    input_dir=bucket_name,\n",
    "    fs=s3_fs,\n",
    "    recursive=True,\n",
    ")\n",
    "\n",
    "all_docs = await reader.aload_data()\n",
    "\n",
    "print(len(all_docs))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llamaindex",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
