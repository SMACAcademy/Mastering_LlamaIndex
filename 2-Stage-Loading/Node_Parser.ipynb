{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import Document\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "\n",
    "# Initialize the node parser with chunk size and overlap\n",
    "node_parser = SentenceSplitter(chunk_size=1024, chunk_overlap=20)\n",
    "\n",
    "# Define a document\n",
    "documents = [Document(text=\"This is a long text that needs to be chunked into manageable parts for processing.\")]\n",
    "\n",
    "# Parse the document into nodes\n",
    "nodes = node_parser.get_nodes_from_documents(documents, show_progress=False)\n",
    "\n",
    "# Display the nodes\n",
    "for node in nodes:\n",
    "    print(f\"Node ID: {node.node_id}, Text: {node.text}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import SimpleDirectoryReader\n",
    "from llama_index.core.ingestion import IngestionPipeline\n",
    "from llama_index.core.node_parser import TokenTextSplitter\n",
    "\n",
    "# Load documents from a directory\n",
    "documents = SimpleDirectoryReader(input_files=['../data/2022 Q3 AAPL.pdf']).load_data()\n",
    "\n",
    "# Set up a transformation pipeline with a TokenTextSplitter\n",
    "pipeline = IngestionPipeline(transformations=[TokenTextSplitter(chunk_size=512, chunk_overlap=50)])\n",
    "\n",
    "# Run the pipeline to generate nodes\n",
    "nodes = pipeline.run(documents=documents)\n",
    "\n",
    "# Display the nodes\n",
    "for node in nodes:\n",
    "    print(f\"Node ID: {node.node_id}, Text: {node.text}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes[1].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import SimpleDirectoryReader, Settings\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "\n",
    "# Load documents\n",
    "documents = SimpleDirectoryReader(input_files=['../data/2022 Q3 AAPL.pdf']).load_data()\n",
    "\n",
    "# Set global settings for node parsing\n",
    "Settings.text_splitter = SentenceSplitter(chunk_size=1024, chunk_overlap=20)\n",
    "\n",
    "# The global setting will be used in all index operations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import SimpleDirectoryReader, VectorStoreIndex\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "\n",
    "# Load documents\n",
    "documents = SimpleDirectoryReader(input_files=['../data/2022 Q3 AAPL.pdf']).load_data()\n",
    "\n",
    "from llama_index.embeddings.ollama import OllamaEmbedding\n",
    "\n",
    "ollama_embedding = OllamaEmbedding(\n",
    "    model_name=\"nomic-embed-text:latest\",  # Replace with your desired model\n",
    "    base_url=\"http://localhost:11434\",  # Ensure Ollama is running at this endpoint\n",
    "    ollama_additional_kwargs={\"mirostat\": 0} #Mirostat is a technique for controlling perplexity and balancing the text generation process in large language models (LLMs).\n",
    ")  \n",
    "\n",
    "# Define transformations for a specific index\n",
    "index = VectorStoreIndex.from_documents(\n",
    "    documents,\n",
    "    transformations=[SentenceSplitter(chunk_size=1024, chunk_overlap=20)],\n",
    "    embed_model=ollama_embedding ,\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llamaindex",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
